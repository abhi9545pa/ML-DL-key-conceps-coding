{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7be5559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objs as go\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e91ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('task_b.csv')\n",
    "data=data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5a214b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-195.871045</td>\n",
       "      <td>-14843.084171</td>\n",
       "      <td>5.532140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1217.183964</td>\n",
       "      <td>-4068.124621</td>\n",
       "      <td>4.416082</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.138451</td>\n",
       "      <td>4413.412028</td>\n",
       "      <td>0.425317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363.824242</td>\n",
       "      <td>15474.760647</td>\n",
       "      <td>1.094119</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-768.812047</td>\n",
       "      <td>-7963.932192</td>\n",
       "      <td>1.870536</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1            f2        f3    y\n",
       "0  -195.871045 -14843.084171  5.532140  1.0\n",
       "1 -1217.183964  -4068.124621  4.416082  1.0\n",
       "2     9.138451   4413.412028  0.425317  0.0\n",
       "3   363.824242  15474.760647  1.094119  0.0\n",
       "4  -768.812047  -7963.932192  1.870536  0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=data[['f1','f2','f3']].values\n",
    "Y=data['y'].values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f33f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1    0.067172\n",
       "f2   -0.017944\n",
       "f3    0.839060\n",
       "y     1.000000\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ecf8a1",
   "metadata": {},
   "source": [
    "\n",
    "<strong><font color='red'> SGD without standarscaling</font></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f9805c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight of the feature sgd with log_loss [[-5810.35602682 -7568.12107298 11196.01895478]]\n",
      "weight of the feature sgd with hinge-loss [[13548.37300582 19610.41444714  9910.89116627]]\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.SGDClassifier(loss='log')\n",
    "clf.fit(X,Y)\n",
    "print(\"weight of the feature sgd with log_loss\",clf.coef_)\n",
    "clf = linear_model.SGDClassifier(loss='hinge')\n",
    "clf.fit(X,Y)\n",
    "print(\"weight of the feature sgd with hinge-loss\",clf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff0dc4",
   "metadata": {},
   "source": [
    "### 1. According to sgdclassifier with log_loss,The feature importance is given by weight the respective features and ranking are :-var(F3)  >>  var(F1)  >>  Var(F2)\n",
    "### 2. According to sgdclassifier with hinge_loss, The feature importance is given by :- var(F1)  >>  var(F3)  >>  Var(F2)\n",
    "### 3. Each time we run the model there is lot change in weights that means there is more variance (std-dev) in data which leads into change in features importance each time.\n",
    "### 4. Because of variance(std-dev) in data which result into the high weight in feature but there are not important to find the feature importances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d075d9",
   "metadata": {},
   "source": [
    "<strong><font color='green'> SGD with standarscaling</font></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e2c54f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.60927123  0.02583157 21.94870556]] weight of the features 'by MinMaxScaler' and 'logloss' \n",
      "[[-2.39090927 -0.31120328 11.27580304]] weight of the features 'by StandarScaler' and 'logloss' \n",
      "****************************************************************************************************\n",
      "[[-4.70015974  1.35097432 36.41125463]] weight of the features 'by MinMaxScaler' and 'hinge-loss'\n",
      "[[-5.65847531 -3.92804409 27.30465125]] weight of the features 'by StandarScaler' and 'hinge-loss'\n"
     ]
    }
   ],
   "source": [
    "Sx=MinMaxScaler()\n",
    "sx=StandardScaler()\n",
    "\n",
    "scale1=sx.fit_transform(X)\n",
    "scale=Sx.fit_transform(X)\n",
    "\n",
    "clf = linear_model.SGDClassifier(loss='log')\n",
    "\n",
    "clf.fit(scale,Y)\n",
    "print(clf.coef_,\"weight of the features 'by MinMaxScaler' and 'logloss' \")\n",
    "clf.fit(scale1,Y)\n",
    "print(clf.coef_,\"weight of the features 'by StandarScaler' and 'logloss' \")\n",
    "print(\"*\"*100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf = linear_model.SGDClassifier(loss='hinge')\n",
    "clf.fit(scale,Y)\n",
    "print(clf.coef_,\"weight of the features 'by MinMaxScaler' and 'hinge-loss'\")\n",
    "clf.fit(scale1,Y)\n",
    "print(clf.coef_,\"weight of the features 'by StandarScaler' and 'hinge-loss'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4c7ee7",
   "metadata": {},
   "source": [
    "### 1. After StandarScaling the model's output is more consistence.\n",
    "### 2. After standardization there is no more effect of varience and weight of feature shows proper importances.\n",
    "### 3. SGD classifier with log_loss and hinge_loss  after standarscaling feature importance change :- var(F3)  >>  var(F2)  >>  var(F1),Weight of feature 1 and 2 reduce more compare to 3 and feature 3 is most importance feature.\n",
    "### 4. Feature weight is proportional to the correlation of the feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cea203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
